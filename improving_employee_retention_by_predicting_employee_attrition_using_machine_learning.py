# -*- coding: utf-8 -*-
"""Task 5. Improving Employee Retention by Predicting Employee Attrition Using Machine Learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GWZWwo_rjDj-RDMM1GutnLjwfO3mvlhO

## Task 5. Improving Employee Retention by Predicting Employee Attrition Using Machine Learning-Copy1
"""

# Commented out IPython magic to ensure Python compatibility.
# importing libraries yang dibutuhkan
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.datasets import make_blobs
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.model_selection import cross_validate
from sklearn.ensemble import RandomForestClassifier
# %matplotlib inline
import warnings
warnings.filterwarnings("ignore")

#import csv dari lokal komputer (file csv)
df = pd.read_csv('/content/sample_data/Improving Employee Retention by Predicting Employee Attrition Using Machine Learning.csv')
df.sample(5)

df.info()

df.isna().sum()

""" Terdapat Missing Values pada fitur ['SkorKepuasanPegawai', 'JumlahKeikutsertaanProjek', 'JumlahKeterlambatanSebulanTerakhir', 'JumlahKetidakhadiran, 'IkutProgramLOP', 'AlasanResign']"""

df.describe()

"""# Data Cleansing"""

#Mengisi nilai Null Value menggunakan nilai mean
df['SkorKepuasanPegawai'].fillna(df['SkorKepuasanPegawai'].mean(), inplace=True)
df['JumlahKeikutsertaanProjek'].fillna(df['JumlahKeikutsertaanProjek'].mean(), inplace=True)
df['JumlahKeterlambatanSebulanTerakhir'].fillna(df['JumlahKeterlambatanSebulanTerakhir'].mean(), inplace=True)
df['JumlahKetidakhadiran'].fillna(df['JumlahKetidakhadiran'].mean(), inplace=True)

# Mengisi missing value menggunakan data yang paling sering muncul
df['AlasanResign'].fillna(df['AlasanResign'].mode()[0], inplace=True)

df.drop(columns=['IkutProgramLOP'], inplace=True)

df.isna().sum()

# Ganti nilai 'yes' menjadi 1
df['PernahBekerja'] = df['PernahBekerja'].replace('yes','1')

#Melihat nilai Unique dalam tiap kolom
for col in df.columns:
    print("{} have {} unique values: {}".format(col, df[col].nunique(), df[col].dtypes))
    if df[col].dtypes == 'int64' or df[col].dtypes == 'float64' or df[col].dtypes == 'object':
        print("{} values: {}".format(col,df[col].unique()))
        print('-' * 100)

df.drop(columns = ['PernahBekerja'], inplace=True)

df.isna().sum()

df.duplicated().sum()

"""# Annual Report On Employee Number Changes"""

df_new = df.copy()

# Mengonversi tanggal hiring dan resign menjadi tahun
df_new['TahunHiring'] = pd.to_datetime(df_new['TanggalHiring'], errors='coerce').dt.year
df_new['TahunResign'] = pd.to_datetime(df_new['TanggalResign'], errors='coerce').dt.year

# Menghitung jumlah karyawan yang masuk berdasarkan tahun hiring
jumlah_masuk = df_new.groupby('TahunHiring').size().reset_index(name='JumlahMasuk')

# Menghitung jumlah karyawan yang keluar berdasarkan tahun resign
jumlah_keluar = df_new.groupby('TahunResign').size().reset_index(name='JumlahKeluar')

# Menggunakan outer join untuk menggabungkan tabel jumlah karyawan yang masuk dan keluar berdasarkan tahun
gabungan_masuk_keluar = pd.merge(jumlah_masuk, jumlah_keluar, how='outer', left_on='TahunHiring', right_on='TahunResign')

# Mengganti nama kolom untuk kejelasan
gabungan_masuk_keluar = gabungan_masuk_keluar.rename(columns={'TahunHiring': 'Tahun', 'TahunResign': 'TahunResign'})

# Langkah 3: Melakukan Imputasi pada Data Tahun yang Kosong

# Melakukan imputasi pada data tahun yang kosong
gabungan_masuk_keluar['Tahun'] = gabungan_masuk_keluar['Tahun'].fillna(gabungan_masuk_keluar['TahunResign'])
gabungan_masuk_keluar = gabungan_masuk_keluar.drop(columns=['TahunResign'])

# Mengisi nilai null dengan 0 pada kolom JumlahMasuk dan JumlahKeluar
gabungan_masuk_keluar['JumlahMasuk'] = gabungan_masuk_keluar['JumlahMasuk'].fillna(0).astype(int)
gabungan_masuk_keluar['JumlahKeluar'] = gabungan_masuk_keluar['JumlahKeluar'].fillna(0).astype(int)

# Menampilkan hasil
gabungan_masuk_keluar = gabungan_masuk_keluar.sort_values(by='Tahun').reset_index(drop=True)
gabungan_masuk_keluar

pip install waterfallcharts

import waterfall_chart

# Menghitung total karyawan yang resign setiap tahunnya
gabungan_masuk_keluar['TotalResign'] = gabungan_masuk_keluar['JumlahKeluar'].cumsum()

# Menghitung total karyawan yang masih bertahan setiap tahunnya
gabungan_masuk_keluar['TotalMasuk'] = gabungan_masuk_keluar['JumlahMasuk'].cumsum()

# Menghitung total karyawan yang masih bertahan setiap tahunnya (dengan mengurangkan total resign)
gabungan_masuk_keluar['TotalBertahan'] = gabungan_masuk_keluar['TotalMasuk'] - gabungan_masuk_keluar['TotalResign']

# Menghitung perubahan jumlah karyawan setiap tahunnya
gabungan_masuk_keluar['Perubahan'] = gabungan_masuk_keluar['TotalBertahan'].diff().fillna(gabungan_masuk_keluar['TotalBertahan'])

# Membuat Plot untuk Menunjukkan Perubahan Kenaikan dan Penurunan Setiap Tahun

# Data yang akan digunakan untuk waterfall chart
data = gabungan_masuk_keluar[['Tahun', 'Perubahan']]

# Mengonversi tahun dan perubahan ke list untuk plot
tahun = data['Tahun'].tolist()
perubahan = data['Perubahan'].tolist()

# Menyediakan data untuk plot
waterfall_data = list(zip(tahun, perubahan))

# Membuat plot waterfall chart
plt.figure(figsize=(30, 20))
waterfall_chart.plot(tahun, perubahan, net_label='Total Karyawan Bertahan', rotation_value=45, formatting='{:.0f}')

# Menambahkan judul dan label
plt.title('Perubahan Jumlah Karyawan Setiap Tahun')
plt.xlabel('Tahun')
plt.ylabel('Perubahan Jumlah Karyawan')
plt.grid(True)
plt.show()

# Menampilkan hasil perhitungan
gabungan_masuk_keluar[['Tahun', 'TotalMasuk', 'TotalResign', 'TotalBertahan', 'Perubahan']]

"""# Resign Reason Analysis For Employee Attrition Management Strategy"""

# Filter data untuk yang sudah resign dan yang belum resign
resigned_df = df_new[df_new['AlasanResign'] != 'masih_bekerja']
not_resigned_df = df_new[df_new['AlasanResign'] == 'masih_bekerja']

# Agregasi jumlah karyawan berdasarkan pekerjaan dan status resign
resigned_agg = resigned_df.groupby('Pekerjaan').size().reset_index(name='Jumlah_Resign')

not_resigned_agg = not_resigned_df.groupby('Pekerjaan').size().reset_index(name='Jumlah_Not_Resign')

# Display the first few rows of each DataFrame
resigned_agg.head(), not_resigned_agg.head()

# Gabungkan kedua DataFrame
merged_df = pd.merge(resigned_agg, not_resigned_agg, on='Pekerjaan', how='outer').fillna(0)

# Display the merged DataFrame
merged_df.head()

# Tambahkan kolom jumlah employee
merged_df['Jumlah_Employee'] = merged_df['Jumlah_Resign'] + merged_df['Jumlah_Not_Resign']

# Tambahkan kolom persentase employee yang belum resign
merged_df['Persentase_Not_Resign'] = merged_df['Jumlah_Not_Resign'] / merged_df['Jumlah_Employee'] * 100

# Display the final DataFrame
merged_df

# Prepare the data for Sunburst Chart
sunburst_data = merged_df.copy()
sunburst_data['Persentase_Not_Resign'] = sunburst_data['Persentase_Not_Resign'].round(2)  # Round percentages for better display

# Create Sunburst Chart
fig = px.sunburst(
    sunburst_data,
    path=['Pekerjaan'],
    values='Persentase_Not_Resign',
    title='Persentase Employee yang Masih Ada Berdasarkan Divisi Pekerjaan',
    color='Persentase_Not_Resign',
    color_continuous_scale='RdYlGn'
)

# Show the plot
fig.show()

# Cari divisi dengan jumlah resign tertinggi
highest_resign_division = resigned_df['Pekerjaan'].value_counts().idxmax()
print(f"Divisi dengan tingkat resign tertinggi: {highest_resign_division}")

# Filter data untuk divisi dengan tingkat resign tertinggi
highest_resign_division_df = resigned_df[resigned_df['Pekerjaan'] == highest_resign_division]

# Agregasi data berdasarkan Jenjang Karir, Performa Karyawan, dan Alasan Resign
aggregation = highest_resign_division_df.groupby(['JenjangKarir', 'PerformancePegawai', 'AlasanResign']).size().reset_index(name='Jumlah_Resign')

# Tampilkan tabel agregasi
aggregation

# Create Sunburst Chart
fig = px.sunburst(
    aggregation,
    path=['JenjangKarir', 'PerformancePegawai', 'AlasanResign'],
    values='Jumlah_Resign',
    color='Jumlah_Resign',
    color_continuous_scale='RdYlGn'
)

# Update the layout for the title
fig.update_layout(
    title={
        'text': f'Jumlah Karyawan yang Resign berdasarkan Jenjang Karir,<br>Performa dan Alasan (Divisi: {highest_resign_division})',
        'y':0.95,
        'x':0.5,
        'xanchor': 'center',
        'yanchor': 'top'
    }
)

# Show the plot
fig.show()

# Filter data untuk divisi "Software Engineer (Front End)"
frontend_resign_df = resigned_df[resigned_df['Pekerjaan'] == 'Software Engineer (Front End)']

# Agregasi data berdasarkan Alasan Resign
frontend_aggregation = frontend_resign_df['AlasanResign'].value_counts().reset_index()
frontend_aggregation.columns = ['AlasanResign', 'Jumlah_Resign']

# Tampilkan tabel agregasi
print(frontend_aggregation)

"""# DATA PREPROCESSING"""

df_prep = df_new.copy()

# Membuang Fitur yang mengandung indentitas pribadi dan yang tidak dibutuhkan
df_prep.drop(columns=['Username','EnterpriseID','AsalDaerah', 'NomorHP','Email','TanggalLahir', 'TanggalPenilaianKaryawan'], inplace =True)

#menambahkan tahun sekarang
tahun_sekarang = 2024

# Mengisi nilai null pada TahunResign menggunakan nilai yang ada pada tahun hiring
df_prep['TahunResign'].fillna(tahun_sekarang, inplace = True)

# Menghapus kolom TahunHiring dan TahunResign
df_prep.drop(columns=['TanggalHiring', 'TanggalResign'], inplace=True)

# Menambahkan fitur Resign
df_prep['Resign'] = df_prep['TahunResign'].apply(lambda x: 0 if x == 2024 else 1)

df_prep.info()

"""## Handling Outliers"""

# Cek Oulier untuk numerical
nums = ['SkorSurveyEngagement', 'SkorKepuasanPegawai','JumlahKeikutsertaanProjek','JumlahKeterlambatanSebulanTerakhir','JumlahKetidakhadiran', 'TahunHiring', 'TahunResign','Resign', ]

df_prep.describe()

#Cek Outliers menggunakan boxplot
plt.figure(figsize = (12, 4))
for i in range (0, len(nums)):
    plt.subplot (1, len(nums), i+1)
    sns.boxplot (y=df_prep[nums[i]], color='gray', orient='v')
    plt.tight_layout()

"""- Terdapat Outliers pada fitur ['SkorSurveyEngagement','JumlahKeikutsertaanProjek', 'JumlahKeterlambatanSebulanTerakhir', 'JumlahKetidakhadiran' ,'TahunHiring']
- Pada fitur Lama_bekerja terdapat nilai negatif, hal tersebut menandakan adanya data yang anomali
"""

# Filter Outlier
print(f'Jumlah baris sebelum memfilter outlier: {len(df_prep)}')

filtered_entries = np.array([True] * len(df_prep))
for col in nums:
    zscore = np.abs(stats.zscore(df_prep[col]))  # Menghitung absolute Z-score
    filtered_entries = filtered_entries & (zscore < 3)

df_prep = df_prep[filtered_entries]

print(f'Jumlah baris setelah memfilter outlier: {len(df_prep)}')

#Cek Outliers setelah dilakukan handling menggunakan boxplot
plt.figure(figsize = (12, 4))
for i in range (0, len(nums)):
    plt.subplot (1, len(nums), i+1)
    sns.boxplot (y=df_prep[nums[i]], color='gray', orient='v')
    plt.tight_layout()

# Buat figure dan axis untuk grid 3x3
fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(20, 15))

# Flatten axes array untuk iterasi yang lebih mudah
axes = axes.flatten()

# Loop melalui semua fitur numerik
for i in range(len(nums)):
    sns.distplot(df_prep[nums[i]], color='gray', ax=axes[i])
    axes[i].set_title(nums[i])

# Jika ada subplot yang tidak digunakan, hapus axis
for i in range(len(nums), len(axes)):
    fig.delaxes(axes[i])

# Menyesuaikan tata letak
plt.tight_layout()

# Menampilkan plot
plt.show()

# Lakukan Normalisasi / Standarisasi
df_prep['SkorSurveyEngagement'] = StandardScaler().fit_transform(df_prep['SkorSurveyEngagement'].values.reshape(len(df_prep), 1))
df_prep['SkorKepuasanPegawai'] = StandardScaler().fit_transform(df_prep['SkorKepuasanPegawai'].values.reshape(len(df_prep), 1))
df_prep['JumlahKeikutsertaanProjek'] = StandardScaler().fit_transform(df_prep['JumlahKeikutsertaanProjek'].values.reshape(len(df_prep), 1))
df_prep['JumlahKeterlambatanSebulanTerakhir'] = StandardScaler().fit_transform(df_prep['JumlahKeterlambatanSebulanTerakhir'].values.reshape(len(df_prep), 1))
df_prep['JumlahKetidakhadiran'] = StandardScaler().fit_transform(df_prep['JumlahKetidakhadiran'].values.reshape(len(df_prep), 1))
df_prep['TahunHiring'] = StandardScaler().fit_transform(df_prep['TahunHiring'].values.reshape(len(df_prep), 1))
df_prep['TahunResign'] = StandardScaler().fit_transform(df_prep['TahunResign'].values.reshape(len(df_prep), 1))

df_prep.describe()

#Cek Fitur Categorical
cats = ['StatusPernikahan', 'JenisKelamin', 'StatusKepegawaian', 'Pekerjaan', 'JenjangKarir', 'PerformancePegawai', 'HiringPlatform', 'TingkatPendidikan', 'AlasanResign']

df_prep[cats].describe()

"""## Feature Encoding"""

df_fe = df_prep.copy()

#Mapping StatusPernikahan menjadi 3 nilai Unique
status_mapping = {
    'Belum_menikah': 'Belum_menikah',
    'Menikah': 'Menikah',
    'Bercerai': 'Bercerai/Lainnya',
    'Lainnya': 'Bercerai/Lainnya',
    '-': 'Bercerai/Lainnya'
}

df_fe['StatusPernikahan'] = df_fe['StatusPernikahan'].map(status_mapping)

pekerjaan_mapping = {
    'Software Engineer (Back End)' : 'Software Engineer',
    'Software Engineer (Front End)' : 'Software Engineer',
    'Software Engineer (UI & UX)' : 'Software Engineer',
    'Software Engineer (Android)' : 'Software Engineer',
    'Software Engineer (iOS)' : 'Software Engineer',
    'Software Architect' : 'Software Engineer',
    'Product Design (UI & UX)' : 'Product Design',
    'Product Design (UX Researcher)' : 'Product Design',
    'Data Analyst' : 'Data',
    'Data Engineer' : 'Data',
    'Product Manager' : 'Product Management',
    'Digital Product Manager' : 'Product Management',
    'Scrum Master' : 'Specialist Roles',
    'Machine Learning Engineer' : 'Specialist Roles',
    'DevOps Engineer' :'Specialist Roles'
}
df_fe['Pekerjaan'] = df_fe['Pekerjaan'].map(pekerjaan_mapping)

hiring_mapping = {
    'Indeed' : 'Online Platform',
    'LinkedIn' : 'Online Platform',
    'CareerBuilder':'Online Platform',
    'Google_Search' : 'Online Platform',
    'Website' : 'Online Platform',
    'On-line_Web_apllication' : 'Online Platform',
    'Diversity_Job_Fair' : 'Offline Platform',
    'Employee_Referral' : 'Offline Platform',
    'Other' : 'Offline Platform'
}
df_fe['HiringPlatform'] = df_fe['HiringPlatform'].map(hiring_mapping)

df_fe[cats].describe()

"""- Label Encoding digunakan untuk fitur JenisKelamin, JenjangKarir, PerformancePegawai, dan Tingkat Pendidikan
- One-Hot Encoding digunakan untuk fitur StatusPernikahan, StatusKepagawaian, Pekerjaan, HiringPlatform, dan AlasanResign
"""

#Feature Encoding Jenis Kelamin
mapping_jk = {
    'Wanita' : 0,
    'Pria' : 1
}
df_fe['JenisKelamin'] = df_fe['JenisKelamin'].map(mapping_jk)

#Feature Encoding Jenjang Karir
mapping_jkr = {
    'Freshgraduate_program' : 0,
    'Mid_level' : 1,
    'Senior_level' : 2
}
df_fe['JenjangKarir'] = df_fe['JenjangKarir'].map(mapping_jkr)

#Feature Encoding Performance Pegawai
mapping_pp = {
    'Sangat_kurang' : 0,
    'Kurang' : 1,
    'Biasa' : 2,
    'Bagus' : 3,
    'Sangat_bagus' : 4
}
df_fe['PerformancePegawai'] = df_fe['PerformancePegawai'].map(mapping_pp)

#Feature Encoding Tingkat Pendidikan
mapping_tp = {
    'Sarjana' : 0,
    'Magister' : 1,
    'Doktor' : 2
}
df_fe['TingkatPendidikan'] = df_fe['TingkatPendidikan'].map(mapping_tp)

df_fe

#Lakukan Feature Encoding untuk Wilayah dan Category menggunakan One-Hot Encoding
df_fe = pd.get_dummies(df_fe, columns=['StatusPernikahan'])
df_fe = pd.get_dummies(df_fe, columns=['StatusKepegawaian'])
df_fe = pd.get_dummies(df_fe, columns=['Pekerjaan'])
df_fe = pd.get_dummies(df_fe, columns=['HiringPlatform'])
df_fe = pd.get_dummies(df_fe, columns=['AlasanResign'])

# Konversi semua kolom boolean menjadi integer
bool_columns = df_fe.select_dtypes(include=['bool']).columns
df_fe[bool_columns] = df_fe[bool_columns].astype(int)

df_fe.info()

df_fe['Resign'] = df_fe.pop('Resign')

# Menghitung matriks korelasi
corr_matrix = df_fe.corr()

# Menampilkan matriks korelasi menggunakan seaborn heatmap
plt.figure(figsize=(20, 20))  # Ukuran plot disesuaikan
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', cbar=True, square=True)
plt.title('Correlation Matrix')
plt.show()

# Identifikasi korelasi tinggi
threshold = 0.9
high_corr_var = np.where(np.abs(corr_matrix) > threshold)
high_corr_var = [(corr_matrix.index[x], corr_matrix.columns[y])
                 for x, y in zip(*high_corr_var) if x != y and x < y]

print("Fitur-fitur dengan korelasi tinggi (di atas 0.9):")
print(high_corr_var)

"""- Berdasarkan hasil dari analisis correlation matrix diatas, maka fitur-fitur yang memiliki korelasi tinggi dan redundan akan di drop
- TahunResign, AlasanResign_masih_bekerja, StatusKepegawaian_Outsource, dan HiringPlatform_Offline Platform
"""

df_fe.drop(columns = ['TahunResign','AlasanResign_masih_bekerja', 'StatusKepegawaian_FullTime','HiringPlatform_Offline Platform'], inplace = True)

df_fe.drop(columns=['StatusPernikahan_Bercerai/Lainnya', 'Pekerjaan_Data','AlasanResign_Product Design (UI & UX)'], inplace = True)

df_fe.info()

"""### Oversampling"""

df_model = df_fe.copy()

X = df_model.drop(columns=["Resign"])
y = df_model['Resign']

# Membagi data menjadi training dan test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

# Lakukan oversampling menggunakan SMOTE pada training set
smote = SMOTE(random_state=42)

# versi 1 dengan CatAnIncome
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Print formatted comparison
print("Data Distribution Before Oversampling:")
print(f"  Total samples: {len(df_prep)}")
print(f"  Count (Resign = 0): {y.value_counts()[0]}")
print(f"  Count (Resign = 1): {y.value_counts()[1]}")

print("Data Distribution After Oversampling:")
print(f"  Total samples: {len(X_train_resampled)}")
print(f"  Count (Resign = 0): {y_train_resampled.value_counts()[0]}")
print(f"  Count (Resign = 1): {y_train_resampled.value_counts()[1]}")

#from statsmodels.stats.outliers_influence import variance_inflation_factor as vif
#vif_data = pd.DataFrame()
#vif_data["feature"] = X_resampled.columns
#vif_data["VIF"] = [vif(X_resampled, i)
#                    for i in range(len(X_resampled.columns))]
#vif_data

"""- Dari hasil VIF Checking terdapat fitur dengan nilai VIF yang tinggi, yaitu fitur SkorSurveyEngagement, SkorKepuasanPegawai, TahunHiring, Pekerjaan_Software Engineer
- Fitur tersebut akan di drop untuk dikorbankan
"""

# Membuang Fitur dari hasil VIF Checking
#X_resampled = X_resampled.drop(columns=['Pekerjaan_Software Engineer'])
#X_resampled = X_resampled.drop(columns=[ 'SkorSurveyEngagement','SkorKepuasanPegawai', 'TahunHiring','Pekerjaan_Software Engineer'])

#vif_data = pd.DataFrame()
#vif_data["feature"] = X_resampled.columns
#vif_data["VIF"] = [vif(X_resampled, i)
 #                   for i in range(len(X_resampled.columns))]
#vif_data

"""- Sudah tidak ada fitur yang memiliki multicolinearity yang tinggi

# Modeling
"""

# split data train dan data test
#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

#X_train.shape, X_test.shape, y_train.shape, y_test.shape

# evaluasi model
#def eval_classification(model):
#    y_pred = model.predict(X_test)
#    y_pred_train = model.predict(X_train)
#    y_pred_proba = model.predict_proba(X_test)
#    y_pred_proba_train = model.predict_proba(X_train)

#    #Dilakukan tuning F1 dengan menghilangkan perhitungan recall
#    print("Accuracy (Test Set): %.4f" % accuracy_score(y_test, y_pred))
#    print("Precision (Test Set): %.4f" % precision_score(y_test, y_pred))
#    print("F1-Score (Test Set): %.4f" % f1_score(y_test, y_pred))
#    print("ROC AUC (Train-proba): %.4f" % roc_auc_score(y_train, y_pred_proba_train[:, 1]))
#    print("ROC AUC (Test-proba): %.4f" % roc_auc_score(y_test, y_pred_proba[:, 1]))

    # Cross-validation dengan precision sebagai metrik
#    score = cross_validate(model, X_train_resampled, y_train_resampled, cv=5, scoring='precision', return_train_score=True)
#    print('Precision (crossval train): '+ str(score['train_score'].mean()))
#    print('Precision (crossval test): '+ str(score['test_score'].mean()))

# Fungsi untuk melatih dan mengevaluasi model
def evaluate_model(model, X_train, y_train, X_test, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    print(f"Model: {model.__class__.__name__}")
    print(classification_report(y_test, y_pred))

    conf_matrix = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title(f'Confusion Matrix - {model.__class__.__name__}')
    plt.show()

    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'Receiver Operating Characteristic (ROC) Curve - {model.__class__.__name__}')
    plt.legend(loc="lower right")
    plt.show()

# Membuat daftar model
models = [
    LogisticRegression(random_state=42),
    RandomForestClassifier(random_state=42),
    GradientBoostingClassifier(random_state=42)
]

# Mengevaluasi setiap model
for model in models:
    evaluate_model(model, X_train_resampled, y_train_resampled, X_test, y_test)

# Melihat feature Importance dari hasil Gradient Boosting
feature_importance = model.feature_importances_

# Mengambil nama kolom dari DataFrame X_df
features = X.columns
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})

# Menampilkan feature importance
print(importance_df.sort_values(by='Importance', ascending=False))

# Mengambil 6 fitur teratas
top_6_features = importance_df.head(6)

# Visualisasi feature importance 6 teratas
plt.figure(figsize=(10, 6))
plt.barh(top_6_features['Feature'], top_6_features['Importance'], color='skyblue')
plt.xlabel('Feature Importance')
plt.title('Top 6 Feature Importance from Gradient Boosting Model')
plt.gca().invert_yaxis()
plt.show()

pip install --upgrade scikit-learn matplotlib

from sklearn.inspection import PartialDependenceDisplay
# Tentukan fitur yang ingin Anda plot
features_to_plot = ['AlasanResign_jam_kerja', 'SkorKepuasanPegawai']

# Membuat dan menampilkan Partial Dependence Plot
PartialDependenceDisplay.from_estimator(model, X, features_to_plot)
plt.show()

pip install lime

import lime
import lime.lime_tabular
explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns, class_names=['0', '1'], discretize_continuous=True)
i = 25
exp = explainer.explain_instance(X_train.values[i], model.predict_proba, num_features=5)
exp.show_in_notebook(show_table=True, show_all=False)

